## A simple example training multi-layer perceptron using MXNET on a portion of the mnist data
mandolin {
    data     = /nfshome/shared/MODEL-SELECTION-EVALS/MNIST-MLP
    mode     = "train"

    trainer {
    	    train-file = ${mandolin.data}/data/train-images-idx3-ubyte
	    test-file  = ${mandolin.data}/data/t10k-images-idx3-ubyte
	    #label-file = ${mandolin.data}/mnist.labels
	    dense-vector-size = 784
	    model-file = ${mandolin.data}/mnist.model
	    #num-epochs = 40
	    num-epochs = 5
	    mini-batch-size = 64	    
	    scale-inputs = true	    
    }


    mx {
       train-labels = ${mandolin.data}/data/train-labels-idx1-ubyte
       test-labels = ${mandolin.data}/data/t10k-labels-idx1-ubyte      
       num-classes = 10
       input-type  = mnist   # special mnist format provided by mxnet
       img {
           channels = 1
           xdim = 28
           ydim = 28   ## flat data should indicate xdim = dimension with ydim = 0
       }
       gpus = []
       cpus = [0]
       save-freq = 100
       
       train {
       	     optimizer = "nag"
	     initial-learning-rate = 0.02
	     momentum = 0.9
	     initializer = "xavier"
       }
       ## Basic MLP
       specification {
         conv1 =  {"data": "input", "type": "mx_conv", "kernel": [5,5], "num_filter": 20},
	 act1  =  {"data": "conv1", "type":"activation", "act_type": "tanh"},
	 pool1 =  {"data": "act1", "type":"pooling", "pool_type": "max", "kernel": [2,2], "stride":[2,2]},
	 conv2 =  {"data": "pool1", "type":"mx_conv", "kernel": [5,5], "num_filter": 50},
	 act2  =  {"data": "conv2", "type":"activation", "act_type": "tanh"},
	 pool2 =  {"data": "act2", "type":"pooling", "pool_type": "max", "kernel": [2,2], "stride":[2,2]},
	 flatten = {"data": "pool2", "type": "flatten"},
	 fcFinal =  {"data": "flatten", "type": "fc", "num_hidden": 500},
	 actFinal = {"data": "fcFinal", "type": "activation", "act_type": "tanh"},
	 outFc = {"data": "actFinal", "type": "fc", "num_hidden": 10},
	 soft1 = {"data": "outFc", "type": "softmax"}
       }
    }

    model-selection {
       acquisition-function = "ucb"
       num-workers = 32      ## number of model evaluators (threads or Spark jobs)
       threads-per-worker = 1 
       worker-batch-size = 1  ## whether to evaluate mulitple models on separate threads within a worker/job
       score-sample-size = 720 ## number of 
       update-frequency = 12   ## how often to update scoring function
       total-evals = 1200       ## how many total models to evaluate before finishing model selection
       categorical = [{"name": "mandolin.mx.train.optimizer", "values": ["sgd","nag","adam"]},
                      {"name": "mandolin.mx.specification.act1.act_type", "values": ["tanh", "relu", "sigmoid"]},
		      {"name": "mandolin.mx.specification.act2.act_type", "values": ["tanh", "relu", "sigmoid"]}]
       real        = [{"name": "mandolin.mx.trainer.initial-learning-rate", "range": [0.001,0.1]}]
       int         = [{"name": "mandolin.mx.specification.fcFinal.num_hidden", "range_by": [300,900,100]},
                      {"name": "mandolin.trainer.mini-batch-size", "range_by": [32,256,32]},
		      {"name": "mandolin.trainer.num-epochs", "range_by": [60,200,20]}
                     ]
    }
    

}
spark {
   master="spark://..." ## replace with Spark Master URL
   executor.cores=16
   cores.max=256
   driver.memory=32g
   serializer=org.apache.spark.serializer.KryoSerializer
   kryo.registrator=org.mitre.mandolin.glp.spark.MandolinKryoRegistrator	
   kryoserializer.buffer.mb=640
   executor.memory=58g
   storage=mem_only
   driver.maxResultSize=2020m
   broadcast.blockSize=128m
   app.name="Mandolin WebURL Model Selection Example"
}


mandolin {
   data = ${?PWD}
   mode = "model-selection"

   trainer {
      train-file        = ${mandolin.data}/weburl.train
      test-file         = ${mandolin.data}/weburl.test
      label-file        = ${mandolin.data}/url.labels  
      num-epochs	= 10
      progress-file	= ${?PWD}/url.train.progress
      synchronous	= false
      threads		= 16
      ensure-sparse	= true

      optimizer {
         method	               = adagrad
	 initial-learning-rate = 1.0
      }

      specification = [
         {"ltype":"InputSparse"},
 	 {"ltype":"SoftMax"}
      ] 
   }
   
   model-selection {
      acquisition-function = "random"
      concurrent-evaluations = 256 ## number of model evaluators (threads or Spark jobs)
      threads-per-worker = 1 
      worker-batch-size = 1  ## whether to evaluate mulitple models on separate threads within a worker/job
      score-sample-size = 600 
      update-frequency = 50   ## how often to update scoring function
      total-evals = 200       ## how many total models to evaluate before finishing model selection
      categorical = [{"name": "mandolin.trainer.optimizer.method", "values": ["adagrad", "sgd", "rmsprop"]}]
      real        = [{"name": "mandolin.trainer.optimizer.initial-learning-rate", "range": [0.001,0.1]}]
      int         = []
   }
}